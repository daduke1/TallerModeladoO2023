{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2023\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Redes Neuronales para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales para clasificación toman como salida valores discretos, generalmente valores binarios (0, 1)\n",
    "- El principal cambio que debemos hacer para clasificación es cambiar la salida de la red neuronal. Se le pone una función de activación no lineal a la salida, generalmente se usa la función Sigmoidal. \n",
    "- Como función de costo se usa el Cross Entropy en lugar de la Suma de Residuales\n",
    "- Si tenemos una salida multiclase, se debe usar la función Softmax en lugar de la sigmoidal\n",
    "\n",
    "**Entonces... ¿qué pasaría si tengo una red neuronal con sólo una capa, donde la función de activación es sigmoidal? sería lo mismo que aplicar una regresión logística**\n",
    "\n",
    "Red neuronal con una capa con función de activación sigmoidal = Regresión logística\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://deeplearningmath.org/images/shallow_NN.png\" width=\"450px\" height=\"280px\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo para salida binaria**\n",
    "\n",
    "Queremos predecir si una persona va a tener diabetes o no (Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "desc = data.describe()\n",
    "info = data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar datos para train y test\n",
    "X = data.iloc[:,0:8]\n",
    "Y = np.ravel(data['Outcome'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6797\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6125 - accuracy: 0.6853\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6068 - accuracy: 0.6909\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.6013 - accuracy: 0.6946\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5963 - accuracy: 0.6927\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5913 - accuracy: 0.6946\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5867 - accuracy: 0.7002\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5825 - accuracy: 0.7002\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5787 - accuracy: 0.7076\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5748 - accuracy: 0.7058\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5709 - accuracy: 0.7076\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5674 - accuracy: 0.7095\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5641 - accuracy: 0.7095\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5607 - accuracy: 0.7114\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5576 - accuracy: 0.7169\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5546 - accuracy: 0.7169\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5519 - accuracy: 0.7225\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5493 - accuracy: 0.7244\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5468 - accuracy: 0.7244\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5443 - accuracy: 0.7207\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5420 - accuracy: 0.7225\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7225\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5376 - accuracy: 0.7263\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5356 - accuracy: 0.7281\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5335 - accuracy: 0.7318\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5315 - accuracy: 0.7318\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5297 - accuracy: 0.7318\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5279 - accuracy: 0.7337\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5261 - accuracy: 0.7374\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5244 - accuracy: 0.7393\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5229 - accuracy: 0.7393\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5214 - accuracy: 0.7393\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5199 - accuracy: 0.7393\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7412\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5172 - accuracy: 0.7430\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5159 - accuracy: 0.7430\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5147 - accuracy: 0.7449\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7467\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5122 - accuracy: 0.7486\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5110 - accuracy: 0.7486\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5098 - accuracy: 0.7505\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5088 - accuracy: 0.7523\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5077 - accuracy: 0.7542\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5067 - accuracy: 0.7542\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5056 - accuracy: 0.7542\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5047 - accuracy: 0.7542\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7542\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5029 - accuracy: 0.7542\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5020 - accuracy: 0.7542\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5011 - accuracy: 0.7561\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.5003 - accuracy: 0.7542\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4994 - accuracy: 0.7523\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7523\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7523\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4970 - accuracy: 0.7523\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4963 - accuracy: 0.7523\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4955 - accuracy: 0.7542\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4948 - accuracy: 0.7542\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4941 - accuracy: 0.7523\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4934 - accuracy: 0.7523\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4926 - accuracy: 0.7523\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4920 - accuracy: 0.7523\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4914 - accuracy: 0.7505\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4908 - accuracy: 0.7523\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4901 - accuracy: 0.7542\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4895 - accuracy: 0.7542\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4890 - accuracy: 0.7542\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4884 - accuracy: 0.7542\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4878 - accuracy: 0.7505\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4873 - accuracy: 0.7486\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4868 - accuracy: 0.7542\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4863 - accuracy: 0.7561\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4858 - accuracy: 0.7579\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4853 - accuracy: 0.7561\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4848 - accuracy: 0.7579\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4844 - accuracy: 0.7598\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4840 - accuracy: 0.7616\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4834 - accuracy: 0.7616\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4830 - accuracy: 0.7616\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4826 - accuracy: 0.7616\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4821 - accuracy: 0.7616\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4816 - accuracy: 0.7635\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7635\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4808 - accuracy: 0.7635\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4804 - accuracy: 0.7635\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4800 - accuracy: 0.7635\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7635\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4791 - accuracy: 0.7654\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4787 - accuracy: 0.7635\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4783 - accuracy: 0.7635\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4780 - accuracy: 0.7635\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4776 - accuracy: 0.7635\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4773 - accuracy: 0.7635\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4769 - accuracy: 0.7635\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4766 - accuracy: 0.7635\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4762 - accuracy: 0.7654\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4759 - accuracy: 0.7635\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4756 - accuracy: 0.7635\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4753 - accuracy: 0.7635\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4749 - accuracy: 0.7635\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4747 - accuracy: 0.7654\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4743 - accuracy: 0.7654\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4740 - accuracy: 0.7654\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7654\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4735 - accuracy: 0.7672\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4732 - accuracy: 0.7672\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4729 - accuracy: 0.7709\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4727 - accuracy: 0.7709\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4724 - accuracy: 0.7709\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7709\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4719 - accuracy: 0.7709\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4717 - accuracy: 0.7709\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7709\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4711 - accuracy: 0.7709\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7709\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4706 - accuracy: 0.7728\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4704 - accuracy: 0.7709\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4702 - accuracy: 0.7709\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4700 - accuracy: 0.7691\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4697 - accuracy: 0.7709\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4695 - accuracy: 0.7691\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4693 - accuracy: 0.7709\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4691 - accuracy: 0.7709\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4689 - accuracy: 0.7728\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4686 - accuracy: 0.7728\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4685 - accuracy: 0.7709\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4683 - accuracy: 0.7728\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4680 - accuracy: 0.7728\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4678 - accuracy: 0.7709\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4677 - accuracy: 0.7709\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4675 - accuracy: 0.7709\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4673 - accuracy: 0.7709\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4671 - accuracy: 0.7709\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4669 - accuracy: 0.7709\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4667 - accuracy: 0.7709\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4665 - accuracy: 0.7709\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4664 - accuracy: 0.7709\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4661 - accuracy: 0.7709\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4660 - accuracy: 0.7709\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4658 - accuracy: 0.7709\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4656 - accuracy: 0.7691\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4655 - accuracy: 0.7709\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4653 - accuracy: 0.7709\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4651 - accuracy: 0.7709\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4650 - accuracy: 0.7709\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4649 - accuracy: 0.7709\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4648 - accuracy: 0.7709\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4646 - accuracy: 0.7728\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4645 - accuracy: 0.7728\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4643 - accuracy: 0.7765\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4641 - accuracy: 0.7765\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7765\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4638 - accuracy: 0.7765\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4637 - accuracy: 0.7747\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4635 - accuracy: 0.7765\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4634 - accuracy: 0.7728\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4632 - accuracy: 0.7765\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4631 - accuracy: 0.7765\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4630 - accuracy: 0.7765\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4628 - accuracy: 0.7765\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4627 - accuracy: 0.7747\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4626 - accuracy: 0.7747\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.4625 - accuracy: 0.7747\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 801us/step - loss: 0.4624 - accuracy: 0.7747\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4623 - accuracy: 0.7747\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4622 - accuracy: 0.7747\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4621 - accuracy: 0.7747\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4620 - accuracy: 0.7747\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4618 - accuracy: 0.7747\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4617 - accuracy: 0.7765\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4617 - accuracy: 0.7765\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4615 - accuracy: 0.7765\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4614 - accuracy: 0.7765\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4613 - accuracy: 0.7784\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4612 - accuracy: 0.7784\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4611 - accuracy: 0.7765\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4610 - accuracy: 0.7784\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4610 - accuracy: 0.7784\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4608 - accuracy: 0.7803\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4607 - accuracy: 0.7803\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4606 - accuracy: 0.7803\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4606 - accuracy: 0.7803\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4605 - accuracy: 0.7803\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4603 - accuracy: 0.7821\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4602 - accuracy: 0.7821\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4601 - accuracy: 0.7821\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4601 - accuracy: 0.7821\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4599 - accuracy: 0.7840\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4598 - accuracy: 0.7858\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4597 - accuracy: 0.7858\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4596 - accuracy: 0.7858\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4595 - accuracy: 0.7858\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 600us/step - loss: 0.4594 - accuracy: 0.7858\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4593 - accuracy: 0.7877\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4593 - accuracy: 0.7877\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4591 - accuracy: 0.7858\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4591 - accuracy: 0.7877\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4590 - accuracy: 0.7858\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 601us/step - loss: 0.4590 - accuracy: 0.7858\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 801us/step - loss: 0.4589 - accuracy: 0.7858\n"
     ]
    }
   ],
   "source": [
    "#Construir red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='tanh', input_shape=(8,))) #se puede cambiar la función de activación\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser \"sigmoidal\" para problemas binomiales (0 y 1)\n",
    "\n",
    "# Configuración del optimizador\n",
    "model.compile(loss='binary_crossentropy',#función de costo\n",
    "              optimizer='sgd',#gradiente descendente\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "model_history=model.fit(X_train, Y_train,epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy function'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ver el performance del modelo en el entrenamiento (accuracy)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 572us/step\n"
     ]
    }
   ],
   "source": [
    "#Usar el modelo para predecir\n",
    "Y_pred = model.predict(X_test) #predecir en términos de decimales o probabilidades\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\") #en términos de 1 y 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23931195],\n",
       "       [0.13346966],\n",
       "       [0.10755724],\n",
       "       [0.29049018],\n",
       "       [0.49255317],\n",
       "       [0.37252128],\n",
       "       [0.02528345],\n",
       "       [0.50317234],\n",
       "       [0.61180747],\n",
       "       [0.805142  ],\n",
       "       [0.18511567],\n",
       "       [0.8804296 ],\n",
       "       [0.44299755],\n",
       "       [0.36230034],\n",
       "       [0.04919357],\n",
       "       [0.45767877],\n",
       "       [0.13075645],\n",
       "       [0.06030593],\n",
       "       [0.7814442 ],\n",
       "       [0.66495496],\n",
       "       [0.21370155],\n",
       "       [0.08790249],\n",
       "       [0.40697953],\n",
       "       [0.07645832],\n",
       "       [0.5577141 ],\n",
       "       [0.85909396],\n",
       "       [0.07260824],\n",
       "       [0.04303092],\n",
       "       [0.32555762],\n",
       "       [0.10869118],\n",
       "       [0.8902206 ],\n",
       "       [0.8683705 ],\n",
       "       [0.8660699 ],\n",
       "       [0.6565186 ],\n",
       "       [0.66969633],\n",
       "       [0.7587509 ],\n",
       "       [0.7919143 ],\n",
       "       [0.21530825],\n",
       "       [0.41220436],\n",
       "       [0.46588233],\n",
       "       [0.04921974],\n",
       "       [0.6000842 ],\n",
       "       [0.5126642 ],\n",
       "       [0.41024107],\n",
       "       [0.05803923],\n",
       "       [0.56231654],\n",
       "       [0.7014151 ],\n",
       "       [0.18238798],\n",
       "       [0.38254872],\n",
       "       [0.8902534 ],\n",
       "       [0.04517426],\n",
       "       [0.7707695 ],\n",
       "       [0.87491804],\n",
       "       [0.31973648],\n",
       "       [0.1559164 ],\n",
       "       [0.04711512],\n",
       "       [0.80628717],\n",
       "       [0.02546952],\n",
       "       [0.4909207 ],\n",
       "       [0.7766984 ],\n",
       "       [0.72800493],\n",
       "       [0.2713792 ],\n",
       "       [0.36248532],\n",
       "       [0.3910151 ],\n",
       "       [0.12872311],\n",
       "       [0.53922766],\n",
       "       [0.04086929],\n",
       "       [0.75096905],\n",
       "       [0.04816863],\n",
       "       [0.7980696 ],\n",
       "       [0.7919828 ],\n",
       "       [0.09500112],\n",
       "       [0.18623605],\n",
       "       [0.13296966],\n",
       "       [0.08600253],\n",
       "       [0.35066706],\n",
       "       [0.1267898 ],\n",
       "       [0.13193291],\n",
       "       [0.1669861 ],\n",
       "       [0.27960226],\n",
       "       [0.72367877],\n",
       "       [0.10031994],\n",
       "       [0.0637594 ],\n",
       "       [0.36180326],\n",
       "       [0.29755175],\n",
       "       [0.87625283],\n",
       "       [0.8366483 ],\n",
       "       [0.42875764],\n",
       "       [0.09503316],\n",
       "       [0.07415818],\n",
       "       [0.05979957],\n",
       "       [0.33616012],\n",
       "       [0.02536074],\n",
       "       [0.4466832 ],\n",
       "       [0.540441  ],\n",
       "       [0.67688805],\n",
       "       [0.43511793],\n",
       "       [0.09446812],\n",
       "       [0.6863117 ],\n",
       "       [0.12210888],\n",
       "       [0.64882916],\n",
       "       [0.08944247],\n",
       "       [0.6275932 ],\n",
       "       [0.62222826],\n",
       "       [0.69593453],\n",
       "       [0.23005015],\n",
       "       [0.23668629],\n",
       "       [0.70718324],\n",
       "       [0.21584494],\n",
       "       [0.58374244],\n",
       "       [0.05707293],\n",
       "       [0.4381528 ],\n",
       "       [0.04557278],\n",
       "       [0.8042036 ],\n",
       "       [0.20169885],\n",
       "       [0.25137064],\n",
       "       [0.6731719 ],\n",
       "       [0.22673506],\n",
       "       [0.04975281],\n",
       "       [0.51110786],\n",
       "       [0.05552275],\n",
       "       [0.20339604],\n",
       "       [0.17229377],\n",
       "       [0.1240503 ],\n",
       "       [0.33699113],\n",
       "       [0.30699125],\n",
       "       [0.07886731],\n",
       "       [0.7690434 ],\n",
       "       [0.7672213 ],\n",
       "       [0.83886236],\n",
       "       [0.6805436 ],\n",
       "       [0.8688084 ],\n",
       "       [0.1384757 ],\n",
       "       [0.4031652 ],\n",
       "       [0.71627986],\n",
       "       [0.11059961],\n",
       "       [0.19812708],\n",
       "       [0.6937142 ],\n",
       "       [0.84646934],\n",
       "       [0.02333845],\n",
       "       [0.05947813],\n",
       "       [0.04216455],\n",
       "       [0.19127195],\n",
       "       [0.61453867],\n",
       "       [0.10284662],\n",
       "       [0.2855814 ],\n",
       "       [0.17217155],\n",
       "       [0.02823067],\n",
       "       [0.38112414],\n",
       "       [0.7721378 ],\n",
       "       [0.13909906],\n",
       "       [0.52343434],\n",
       "       [0.36208668],\n",
       "       [0.15417057],\n",
       "       [0.02729604],\n",
       "       [0.5914735 ],\n",
       "       [0.34792933],\n",
       "       [0.5940321 ],\n",
       "       [0.7771895 ],\n",
       "       [0.1490851 ],\n",
       "       [0.5326293 ],\n",
       "       [0.7162897 ],\n",
       "       [0.15661602],\n",
       "       [0.02529858],\n",
       "       [0.09186164],\n",
       "       [0.84817165],\n",
       "       [0.05492945],\n",
       "       [0.30572486],\n",
       "       [0.79397964],\n",
       "       [0.62859714],\n",
       "       [0.684215  ],\n",
       "       [0.18916915],\n",
       "       [0.3342793 ],\n",
       "       [0.85037744],\n",
       "       [0.67633355],\n",
       "       [0.12488963],\n",
       "       [0.2288068 ],\n",
       "       [0.23151173],\n",
       "       [0.26217026],\n",
       "       [0.4184447 ],\n",
       "       [0.49651894],\n",
       "       [0.65023607],\n",
       "       [0.46346393],\n",
       "       [0.7940997 ],\n",
       "       [0.7427694 ],\n",
       "       [0.07666248],\n",
       "       [0.046159  ],\n",
       "       [0.11707362],\n",
       "       [0.8471188 ],\n",
       "       [0.46142924],\n",
       "       [0.0556134 ],\n",
       "       [0.07342935],\n",
       "       [0.64054304],\n",
       "       [0.38802907],\n",
       "       [0.1514852 ],\n",
       "       [0.05305085],\n",
       "       [0.04480715],\n",
       "       [0.05197029],\n",
       "       [0.23383982],\n",
       "       [0.73472846],\n",
       "       [0.18906276],\n",
       "       [0.10821796],\n",
       "       [0.33676365],\n",
       "       [0.42575008],\n",
       "       [0.73119307],\n",
       "       [0.08272792],\n",
       "       [0.0728612 ],\n",
       "       [0.17763516],\n",
       "       [0.92604065],\n",
       "       [0.7344178 ],\n",
       "       [0.34301195],\n",
       "       [0.19774842],\n",
       "       [0.08688091],\n",
       "       [0.0970023 ],\n",
       "       [0.7225247 ],\n",
       "       [0.09785033],\n",
       "       [0.7917579 ],\n",
       "       [0.46852046],\n",
       "       [0.36186263],\n",
       "       [0.8398819 ],\n",
       "       [0.64738536],\n",
       "       [0.1037935 ],\n",
       "       [0.05394436],\n",
       "       [0.12999661],\n",
       "       [0.08519886],\n",
       "       [0.42533657],\n",
       "       [0.27954942],\n",
       "       [0.28947046],\n",
       "       [0.3698952 ],\n",
       "       [0.16370079],\n",
       "       [0.17626382]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 500us/step\n",
      "17/17 [==============================] - 0s 500us/step\n",
      "17/17 [==============================] - 0s 438us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.786 \t 0.719 \t 0.638\n",
      "  Test \t 0.745 \t 0.633 \t 0.625\n"
     ]
    }
   ],
   "source": [
    "#métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score) #mientras más grandes mejor\n",
    "\n",
    "#métricas en el train\n",
    "accu_train = accuracy_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "prec_train = precision_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "reca_train = recall_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "\n",
    "#métricas en el test\n",
    "accu_test = accuracy_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Multiclase**\n",
    "\n",
    "- Aunque las salidas de la red neuronal están limitadas a un rango de valores entre 0 y 1, no se garantiza que la suma de estos sea igual a 1\n",
    "- Transformar las salidas para que puedan ser usadas como probabilidades ayuda mucho a la interpretabilidad de las predicciones\n",
    "- Transformación Softmax\n",
    "\n",
    "$$\\hat{p}_{l,i}^{*} = \\frac{e^{\\hat{y}_{l,i}}}{\\sum{e^{\\hat{y}_{l,i}}}}$$\n",
    "\n",
    "- $\\hat{y}_{1}=0.25$, $\\hat{y}_{2}=0.76$, $\\hat{y}_{3}=0.1$\n",
    "\n",
    "- $\\hat{p}_{1}=0.3099$, $\\hat{p}_{2}=0.4717$, $\\hat{p}_{3}=0.2184$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adam\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y #tres tipos de flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la variable target a dummies para poderla trabajar en la red neuronal\n",
    "dummy_y = to_categorical(Y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 2.1977 - accuracy: 0.3083 - val_loss: 1.4053 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4405 - accuracy: 0.4167 - val_loss: 0.8769 - val_accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9195 - accuracy: 0.6500 - val_loss: 0.8473 - val_accuracy: 0.7000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8634 - accuracy: 0.6500 - val_loss: 0.8082 - val_accuracy: 0.4333\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8115 - accuracy: 0.5000 - val_loss: 0.7726 - val_accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7723 - accuracy: 0.7000 - val_loss: 0.7225 - val_accuracy: 0.8667\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7201 - accuracy: 0.8000 - val_loss: 0.6506 - val_accuracy: 0.7000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6690 - accuracy: 0.6583 - val_loss: 0.6118 - val_accuracy: 0.7000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6278 - accuracy: 0.6667 - val_loss: 0.5887 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5947 - accuracy: 0.9083 - val_loss: 0.5728 - val_accuracy: 0.9000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5712 - accuracy: 0.9583 - val_loss: 0.5237 - val_accuracy: 0.7000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5418 - accuracy: 0.6917 - val_loss: 0.5225 - val_accuracy: 0.7000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5542 - accuracy: 0.6583 - val_loss: 0.4842 - val_accuracy: 0.7667\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4989 - accuracy: 0.7167 - val_loss: 0.4777 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4889 - accuracy: 0.9167 - val_loss: 0.4564 - val_accuracy: 0.7667\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4720 - accuracy: 0.7000 - val_loss: 0.4689 - val_accuracy: 0.7000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4906 - accuracy: 0.6667 - val_loss: 0.4469 - val_accuracy: 0.9667\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4620 - accuracy: 0.9333 - val_loss: 0.4376 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4519 - accuracy: 0.9250 - val_loss: 0.4174 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4332 - accuracy: 0.7750 - val_loss: 0.4184 - val_accuracy: 0.9667\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4257 - accuracy: 0.9583 - val_loss: 0.4017 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4134 - accuracy: 0.8750 - val_loss: 0.4019 - val_accuracy: 0.7667\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4200 - accuracy: 0.7500 - val_loss: 0.3875 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3990 - accuracy: 0.8750 - val_loss: 0.4093 - val_accuracy: 0.9000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4149 - accuracy: 0.9333 - val_loss: 0.3771 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3906 - accuracy: 0.8333 - val_loss: 0.4185 - val_accuracy: 0.7333\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4385 - accuracy: 0.7000 - val_loss: 0.3811 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3872 - accuracy: 0.9583 - val_loss: 0.3537 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3741 - accuracy: 0.8750 - val_loss: 0.3624 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3736 - accuracy: 0.9500 - val_loss: 0.3483 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3467 - accuracy: 0.9583 - val_loss: 0.4185 - val_accuracy: 0.7333\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4262 - accuracy: 0.7083 - val_loss: 0.3831 - val_accuracy: 0.8667\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4075 - accuracy: 0.8583 - val_loss: 0.3271 - val_accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3604 - accuracy: 0.8917 - val_loss: 0.3453 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3658 - accuracy: 0.8167 - val_loss: 0.3513 - val_accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3536 - accuracy: 0.9500 - val_loss: 0.3165 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3242 - accuracy: 0.9083 - val_loss: 0.3207 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3222 - accuracy: 0.9667 - val_loss: 0.3099 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3141 - accuracy: 0.9667 - val_loss: 0.3007 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3099 - accuracy: 0.9583 - val_loss: 0.3258 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3362 - accuracy: 0.8583 - val_loss: 0.3022 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3135 - accuracy: 0.9083 - val_loss: 0.2885 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2957 - accuracy: 0.9583 - val_loss: 0.2783 - val_accuracy: 0.9667\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2841 - accuracy: 0.9500 - val_loss: 0.2750 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2809 - accuracy: 0.9583 - val_loss: 0.2702 - val_accuracy: 0.9667\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2771 - accuracy: 0.9500 - val_loss: 0.3080 - val_accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3075 - accuracy: 0.9417 - val_loss: 0.3024 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3145 - accuracy: 0.8750 - val_loss: 0.2627 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2713 - accuracy: 0.9667 - val_loss: 0.2842 - val_accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2949 - accuracy: 0.9417 - val_loss: 0.2587 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2605 - accuracy: 0.9667 - val_loss: 0.2687 - val_accuracy: 0.9667\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2687 - accuracy: 0.9750 - val_loss: 0.2495 - val_accuracy: 0.9667\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2529 - accuracy: 0.9583 - val_loss: 0.2432 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2540 - accuracy: 0.9583 - val_loss: 0.2941 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2991 - accuracy: 0.8750 - val_loss: 0.2401 - val_accuracy: 0.9667\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2401 - accuracy: 0.9667 - val_loss: 0.2797 - val_accuracy: 0.9000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2799 - accuracy: 0.9500 - val_loss: 0.2339 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2371 - accuracy: 0.9667 - val_loss: 0.2330 - val_accuracy: 0.9667\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2357 - accuracy: 0.9583 - val_loss: 0.2681 - val_accuracy: 0.9000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2674 - accuracy: 0.9417 - val_loss: 0.2587 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2673 - accuracy: 0.9083 - val_loss: 0.2288 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2482 - accuracy: 0.9583 - val_loss: 0.2297 - val_accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2368 - accuracy: 0.9500 - val_loss: 0.2356 - val_accuracy: 0.9667\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2420 - accuracy: 0.9500 - val_loss: 0.2463 - val_accuracy: 0.9333\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2511 - accuracy: 0.9417 - val_loss: 0.2194 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2207 - accuracy: 0.9750 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2141 - accuracy: 0.9750 - val_loss: 0.2130 - val_accuracy: 0.9667\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2152 - accuracy: 0.9583 - val_loss: 0.2503 - val_accuracy: 0.9000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2532 - accuracy: 0.9417 - val_loss: 0.2118 - val_accuracy: 0.9667\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2181 - accuracy: 0.9500 - val_loss: 0.2168 - val_accuracy: 0.9667\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2140 - accuracy: 0.9417 - val_loss: 0.2987 - val_accuracy: 0.8667\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2996 - accuracy: 0.9000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2042 - accuracy: 0.9667 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2060 - accuracy: 0.9667 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1975 - accuracy: 0.9667 - val_loss: 0.2213 - val_accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2212 - accuracy: 0.9333 - val_loss: 0.2018 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2073 - accuracy: 0.9583 - val_loss: 0.1945 - val_accuracy: 0.9667\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2005 - accuracy: 0.9583 - val_loss: 0.1963 - val_accuracy: 0.9667\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2033 - accuracy: 0.9417 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.9667 - val_loss: 0.1885 - val_accuracy: 0.9667\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1965 - accuracy: 0.9500 - val_loss: 0.1832 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1943 - accuracy: 0.9583 - val_loss: 0.1773 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1882 - accuracy: 0.9667 - val_loss: 0.1807 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1929 - accuracy: 0.9500 - val_loss: 0.2385 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2414 - accuracy: 0.9083 - val_loss: 0.1940 - val_accuracy: 0.9667\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2114 - accuracy: 0.9500 - val_loss: 0.1834 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1876 - accuracy: 0.9583 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1861 - accuracy: 0.9750 - val_loss: 0.1773 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1786 - accuracy: 0.9833 - val_loss: 0.1894 - val_accuracy: 0.9667\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1931 - accuracy: 0.9500 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1750 - accuracy: 0.9750 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1818 - accuracy: 0.9583 - val_loss: 0.1696 - val_accuracy: 0.9667\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1795 - accuracy: 0.9500 - val_loss: 0.1810 - val_accuracy: 0.9667\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1833 - accuracy: 0.9500 - val_loss: 0.1964 - val_accuracy: 0.9333\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2072 - accuracy: 0.9417 - val_loss: 0.1762 - val_accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1839 - accuracy: 0.9500 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1716 - accuracy: 0.9667 - val_loss: 0.2189 - val_accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2210 - accuracy: 0.9417 - val_loss: 0.2416 - val_accuracy: 0.8000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2458 - accuracy: 0.9000 - val_loss: 0.1585 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1897 - accuracy: 0.9583 - val_loss: 0.1746 - val_accuracy: 0.9667\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1879 - accuracy: 0.9583 - val_loss: 0.1635 - val_accuracy: 0.9667\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1746 - accuracy: 0.9583 - val_loss: 0.1777 - val_accuracy: 0.9667\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1800 - accuracy: 0.9500 - val_loss: 0.2116 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2140 - accuracy: 0.9417 - val_loss: 0.1510 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1624 - accuracy: 0.9667 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1609 - accuracy: 0.9667 - val_loss: 0.1507 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1646 - accuracy: 0.9583 - val_loss: 0.1671 - val_accuracy: 0.9667\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1792 - accuracy: 0.9583 - val_loss: 0.2014 - val_accuracy: 0.9000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2050 - accuracy: 0.9500 - val_loss: 0.1629 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1783 - accuracy: 0.9667 - val_loss: 0.1531 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1581 - accuracy: 0.9667 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1674 - accuracy: 0.9500 - val_loss: 0.1484 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1536 - accuracy: 0.9667 - val_loss: 0.1583 - val_accuracy: 0.9667\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1641 - accuracy: 0.9667 - val_loss: 0.1736 - val_accuracy: 0.9667\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1791 - accuracy: 0.9500 - val_loss: 0.1586 - val_accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1696 - accuracy: 0.9500 - val_loss: 0.1432 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1575 - accuracy: 0.9750 - val_loss: 0.1492 - val_accuracy: 0.9667\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1544 - accuracy: 0.9667 - val_loss: 0.1587 - val_accuracy: 0.9667\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1626 - accuracy: 0.9500 - val_loss: 0.1542 - val_accuracy: 0.9667\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1580 - accuracy: 0.9583 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1529 - accuracy: 0.9750 - val_loss: 0.1594 - val_accuracy: 0.9667\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1668 - accuracy: 0.9667 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1493 - accuracy: 0.9833 - val_loss: 0.1632 - val_accuracy: 0.9667\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1659 - accuracy: 0.9583 - val_loss: 0.1372 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1446 - accuracy: 0.9750 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1507 - accuracy: 0.9750 - val_loss: 0.1660 - val_accuracy: 0.9667\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1730 - accuracy: 0.9500 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1515 - accuracy: 0.9750 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1464 - accuracy: 0.9750 - val_loss: 0.1396 - val_accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1491 - accuracy: 0.9583 - val_loss: 0.1320 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1464 - accuracy: 0.9750 - val_loss: 0.1494 - val_accuracy: 0.9667\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1535 - accuracy: 0.9667 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1426 - accuracy: 0.9750 - val_loss: 0.1527 - val_accuracy: 0.9667\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1561 - accuracy: 0.9583 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1412 - accuracy: 0.9833 - val_loss: 0.1416 - val_accuracy: 0.9667\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1491 - accuracy: 0.9667 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1395 - accuracy: 0.9750 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1489 - accuracy: 0.9667 - val_loss: 0.1334 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1421 - accuracy: 0.9667 - val_loss: 0.1344 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1407 - accuracy: 0.9667 - val_loss: 0.1331 - val_accuracy: 0.9667\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 0.9667 - val_loss: 0.1439 - val_accuracy: 0.9667\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1563 - accuracy: 0.9417 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1320 - accuracy: 0.9750 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1359 - accuracy: 0.9667 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1323 - accuracy: 0.9667 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1340 - accuracy: 0.9667 - val_loss: 0.1631 - val_accuracy: 0.9667\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1652 - accuracy: 0.9417 - val_loss: 0.1793 - val_accuracy: 0.9000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.9417 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1482 - accuracy: 0.9667 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1400 - accuracy: 0.9750 - val_loss: 0.1380 - val_accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1443 - accuracy: 0.9583 - val_loss: 0.1420 - val_accuracy: 0.9667\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1432 - accuracy: 0.9667 - val_loss: 0.1436 - val_accuracy: 0.9667\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1506 - accuracy: 0.9500 - val_loss: 0.1494 - val_accuracy: 0.9667\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1565 - accuracy: 0.9500 - val_loss: 0.1514 - val_accuracy: 0.9667\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1465 - accuracy: 0.9583 - val_loss: 0.2048 - val_accuracy: 0.9000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2096 - accuracy: 0.9333 - val_loss: 0.1553 - val_accuracy: 0.9667\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1650 - accuracy: 0.9500 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1332 - accuracy: 0.9750 - val_loss: 0.1327 - val_accuracy: 0.9667\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1435 - accuracy: 0.9583 - val_loss: 0.1253 - val_accuracy: 0.9667\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1354 - accuracy: 0.9667 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1240 - accuracy: 0.9750 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1243 - accuracy: 0.9750 - val_loss: 0.1356 - val_accuracy: 0.9667\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1415 - accuracy: 0.9583 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1266 - accuracy: 0.9833 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1263 - accuracy: 0.9750 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1227 - accuracy: 0.9750 - val_loss: 0.1116 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1253 - accuracy: 0.9750 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1230 - accuracy: 0.9667 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1283 - accuracy: 0.9667 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1247 - accuracy: 0.9750 - val_loss: 0.1418 - val_accuracy: 0.9333\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1477 - accuracy: 0.9583 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1261 - accuracy: 0.9750 - val_loss: 0.1116 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1166 - accuracy: 0.9750 - val_loss: 0.1347 - val_accuracy: 0.9667\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1369 - accuracy: 0.9583 - val_loss: 0.1406 - val_accuracy: 0.9333\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1536 - accuracy: 0.9417 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1300 - accuracy: 0.9833 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1252 - accuracy: 0.9667 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1205 - accuracy: 0.9833 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1187 - accuracy: 0.9667 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1178 - accuracy: 0.9833 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1166 - accuracy: 0.9750 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1214 - accuracy: 0.9750 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1163 - accuracy: 0.9667 - val_loss: 0.1473 - val_accuracy: 0.9667\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1506 - accuracy: 0.9500 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1217 - accuracy: 0.9667 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.1768 - val_accuracy: 0.9333\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1793 - accuracy: 0.9417 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 0.9833 - val_loss: 0.1551 - val_accuracy: 0.9333\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1546 - accuracy: 0.9583 - val_loss: 0.1401 - val_accuracy: 0.9667\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1473 - accuracy: 0.9583 - val_loss: 0.1261 - val_accuracy: 0.9667\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1331 - accuracy: 0.9833 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1155 - accuracy: 0.9833 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1114 - accuracy: 0.9833 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.1068 - val_accuracy: 0.9667\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.9750 - val_loss: 0.1163 - val_accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.9500 - val_loss: 0.1119 - val_accuracy: 0.9667\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1247 - accuracy: 0.9667 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1139 - accuracy: 0.9667 - val_loss: 0.1136 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "#Construcción de la red neuronal\n",
    "\n",
    " \n",
    "\n",
    "# neural network structure\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))#salida\n",
    "\n",
    " \n",
    "\n",
    "#Gradiente descendente\n",
    "learning_rate=0.1\n",
    "epochs = 200\n",
    "momentum = 0.8\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    " \n",
    "\n",
    "# configuracion del optimizador\n",
    "model.compile(loss='categorical_crossentropy',#funcion de costo\n",
    "              optimizer=sgd,#gradiente descendente\n",
    "              metrics=['accuracy'])\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=100, \n",
    "                   validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficar el categorical crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predecir con el modelo \n",
    "Y_pred = model.predict(X_test) # en términos de probabilidades\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\") # en términos de clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.88980731e-07, 9.06652868e-01, 9.33465362e-02],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [3.57245853e-23, 1.52486924e-03, 9.98475134e-01],\n",
       "       [1.60513380e-07, 8.77156496e-01, 1.22843295e-01],\n",
       "       [4.55779031e-07, 9.04990256e-01, 9.50093716e-02],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [5.98768098e-03, 9.86870885e-01, 7.14138336e-03],\n",
       "       [1.62795591e-12, 2.73724705e-01, 7.26275265e-01],\n",
       "       [4.25144053e-09, 7.28138566e-01, 2.71861404e-01],\n",
       "       [4.96729393e-04, 9.85032856e-01, 1.44704580e-02],\n",
       "       [2.14861722e-11, 4.11566943e-01, 5.88433027e-01],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [2.89813499e-07, 8.93657088e-01, 1.06342576e-01],\n",
       "       [1.64359944e-17, 2.68705767e-02, 9.73129392e-01],\n",
       "       [1.70890926e-04, 9.80343163e-01, 1.94860604e-02],\n",
       "       [2.05841204e-07, 8.84346426e-01, 1.15653336e-01],\n",
       "       [3.07215740e-17, 3.07688117e-02, 9.69231248e-01],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [1.03142252e-10, 5.07365882e-01, 4.92634118e-01],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [1.33435668e-16, 4.22106646e-02, 9.57789302e-01],\n",
       "       [1.75373035e-13, 1.83087572e-01, 8.16912413e-01],\n",
       "       [5.95338123e-14, 1.48797914e-01, 8.51202130e-01],\n",
       "       [3.59769198e-16, 5.21597080e-02, 9.47840273e-01],\n",
       "       [2.83708954e-17, 3.02436352e-02, 9.69756365e-01],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05],\n",
       "       [9.63623226e-01, 3.63525599e-02, 2.42017086e-05]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer ingenería en reversa, para dejar las predicciones en el formato original que teníamos de las \"Y\"\n",
    "uniques, ids = np.unique(Y, return_inverse=True)\n",
    "dummy_y = to_categorical(ids, len(uniques))\n",
    "reverse = uniques[dummy_y.argmax(1)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reverse,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 667us/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.967 \t 0.967 \t 0.967\n",
      "  Test \t 0.967 \t 0.970 \t 0.967\n"
     ]
    }
   ],
   "source": [
    "#Métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "\n",
    "#métricas en el train\n",
    "Y_proba= model.predict(X_train)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_train = accuracy_score(y_train, Y_pred)\n",
    "prec_train = precision_score(y_train, Y_pred,average='weighted')\n",
    "reca_train = recall_score(y_train, Y_pred,average='weighted')\n",
    "\n",
    "\n",
    "#métricas en el test\n",
    "Y_proba= model.predict(X_test)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test, Y_pred)\n",
    "prec_test = precision_score(y_test, Y_pred,average='weighted')\n",
    "reca_test = recall_score(y_test, Y_pred,average='weighted')\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
